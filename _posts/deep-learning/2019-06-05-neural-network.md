---
layout: post
title: 신경망 학습과 손실함수
excerpt: "Deep Learning"
tags: [deep learning, programming, dl]
permalink: /deep-learning/:year/:month/:day/:title/
category : 딥러닝
---

신경망의 특징은 데이터를 보고 학습할 수 있다는 점이다. 매개변수의 값을 데이터를 보고 자동으로 결정한다는 뜻이다.  

예를 들어 숫자를 분류하는 프로그램을 설계한다고 한다면 알고리즘을 직접 설계하는 대신 주어진 데이터를 사용하여 특징을 추출한다.

딥러닝은 종단간 기계학습 (end-to-end machine learning) 이라고도 하는데, 모든 문제를 주어진 데이터 그대로를 입력 데이터로 활용해 학습할 수 있다는 뜻이다.  

기계학습은 데이터를 훈련 데이터(training data)와 시험 데이터(test data)로 나눠 학습과 실험을 수행한다. 훈련 데이터만 사용하고 학습하며 최적의 매개변수를 찾는다. 그다음 평가할때는 시험 데이터를 사용한다.

한 데이터셋에만 지나치게 최적화된 상태를 오버피팅(overfitting)이라고 한다. 오버피팅을 피하는 것이 기계학습의 중요한 과제다.

손실함수란 하나의 지표로 최적의 매개변수 값을 탐색하는 기준이다. 가장 많이 쓰이는 손실함수는 평균제곱오차 (mean squared error, MSE) 이다. 정답과 신경망의 출력의 차를 제곱한것의 합을 평균낸 것이다. 

두번째로 교차 엔트로피 오차를 자주 사용한다. 
![entropy](https://wikimedia.org/api/rest_v1/media/math/render/svg/c6b895514e10a3ce88773852cba1cb1e248ed763)
교차 엔트로피 오차는 정답일 때의 출력이 전체 값을 정하게 된다.

왜 정확도를 사용하여 매개변수 값을 찾지 않고 손실 함수를 사용할까? 그 이유는 신경망 학습에서의 미분의 역할에 있다. 정확도를 지표로 삼지 못하는 이유는 미분 값이 대부분 0이 되기 때문에 매개변수를 갱신할 수 없기 때문이다. 정확도는 매개변수의 변화에는 거의 반응을 보이지 않고, 있더라도 값이 불연속적으로 변화한다.

### Reference
밑바닥부터 시작하는 딥러닝