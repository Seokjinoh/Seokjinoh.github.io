---
layout: post
title: 평가 지표와 측정
excerpt: "Machine Learning"
tags: [machine learning, programming, dl]
permalink: /machine-learning/:year/:month/:day/:title/
category : 머신러닝
---

# 평가 지표와 측정

- 분류 성능 평가에는 정확도를 보통 사용했지만, 데이터셋에 대한 지도 학습 모델의  
성능을 측정하는 방법은 그외에도 많다.
- 불균형 데이터셋에서 예측 성능을 정령화하는 데 정확도는 적절한 측정 방법이 아니다.

  - 최종 목표를 기억하라
    - 비즈니스 지표라고 부르는 애플리케이션의 고차원적인 목표를 생각하라
    - 애플리케이션에서 특정 알고리즘을 선택하여 나타난 결과를 **비즈니스 임팩트** 라고 하는데, 이를 위해 긍정적인 영향을 주는 모델과 매개변수를 선택해야 한다. 하지만 매개변수를 조정할 때 평가 지표와 측정이 필요하다.

- 이진 분류의 평가 지표
  - 오차 행렬은 이진 분류 평가를 나타낼 때 가낭 널리 사용되는 방법 중 하나다.
    - TN(True Negative) / FP(False Positive) / FN(False Negative) / TP(True Positive)
      -  **앞쪽의 T/F는 예측이 맞았는지, 틀렸는지를 뒤의 P와 N은 예측을 Positive로 했는지, Negative로 했는지이다.**
    - FN은 최대한 피해야 하지만 FP는 비교적 중요도가 낮다

  - 불균형 데이터셋
    - 한 클래스가 다른 것보다 훨씬 많은 데이터셋
  - 오차 행렬의 결과를 요약 하는 법은 정확도로 표현하는 것이다.
    - 정확도는 정확히 예측한 수 (TP와 TN)을 전체 샘플 수(오차 행렬의 모든 값)으로 나눈 것이다.
    - 정밀도는 양성으로 예측된 것(TP + FP)중 얼마나 많은 샘플이 진짜 양성(TP)인지 측정하는 것이다.
    - 재현율은 전체 양성 샘플(TP + FN) 중에서 얼마나 많은 샘플이 양성(TP)로 분류되는지를 측정한 것이다.

- 다중 분류의 평가 지표
  - 모두 이진 분류 평가 지표에서 유도됨, 다만 모든 클래스에 대해 평균을 낸 것
  - 클래스가 불균형할 때는 정확도는 좋은 지표가 아님
  - 정확도 외에 오차 행렬과 분류 리포트 등을 일반적으로 사용함
  - 다중 분류에서 불균형 데이터셋을 위해 널리 사용하는 평가 지표는 f1-점수의 다중 분류 버전이다.
    - 한 클래스를 양성 클래스로 두고 다른 클래스는 음성으로 둔 뒤 f1-점수를 계산한다
  - 클래스의 가중치에 따라 macro / weighted / micro 의 방법들이 있다.

- 회귀의 평가 지표
  - 대부분의 애플리케이션에서는 회귀 추정기의 score 메서드에서 이용하는 R^2 만으로도 충분하다.

- 모델 선택에서 평가 지표 사용하기
  - GridSearchCV나 cross_val_score를 사용하여 모델을 선택할 때, AUC와 같은 평가 지표를 사용하고 싶다면?
    - scikit-learn에서 GridSearchCV나 cross_val_score의 scoring 매개변수를 통해 손쉽게 구현 가능하다.

